{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/w-okada/ttsclient/blob/master/w_okada's_TextToSpeech_version_2_x.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNCGmSXbfZRr"
      },
      "source": [
        "### w-okada's Text To Speech Client version 2.x | **Google Colab**\n",
        "\n",
        "## READ ME - VERY IMPORTANT\n",
        "This is an attempt to run [Text To Speech Client](https://github.com/w-okada/ttsclient) on Google Colab, still not perfect but is totally usable.\n",
        "\n",
        "---\n",
        "\n",
        "###Always use Colab GPU (**VERY VERY VERY IMPORTANT!**)\n",
        "You need to use a Colab GPU so the Voice Changer can work faster and better\\\n",
        "Use the menu above and click on **Runtime** » **Change runtime** » **Hardware acceleration** to select a GPU (**T4 is the free one**)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2GYWTHWmRIY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#=================Updated=================\n",
        "# @title **[1]** Clone repository and install dependencies\n",
        "# @markdown This first step will download the latest version of Voice Changer and install the dependencies. **It can take some time to complete.(~5min)**\n",
        "\n",
        "#@markdown ---\n",
        "# @markdown By using Google Drive, you can avoid re-downloading already downloaded versions.\n",
        "\n",
        "\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "import threading\n",
        "import shutil\n",
        "import base64\n",
        "import codecs\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "from typing import Literal, TypeAlias\n",
        "\n",
        "# Configs\n",
        "Run_Cell=0\n",
        "Use_Drive=False #@param {type:\"boolean\"}\n",
        "\n",
        "current_version_hash=None\n",
        "latest_version_hash=None\n",
        "\n",
        "# Check GPU\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available\")\n",
        "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"GPU is not available\")\n",
        "    # sys.exit(\"No GPU available. Change runtime.\")\n",
        "\n",
        "\n",
        "notebook_env=0\n",
        "if os.path.exists('/content'):\n",
        "  notebook_env=1\n",
        "  print(\"Welcome to ColabMod\")\n",
        "  from google.colab import drive\n",
        "\n",
        "elif os.path.exists('/kaggle/working'):\n",
        "  notebook_env=2\n",
        "  print(\"Welcome to Kaggle Mod\")\n",
        "else:\n",
        "  notebook_env=3\n",
        "  print(\"Welcome!\")\n",
        "\n",
        "from IPython.display import clear_output, Javascript\n",
        "\n",
        "if notebook_env==1 and Use_Drive==True:\n",
        "  work_dir = \"/content/drive/MyDrive/ttsclient\"\n",
        "  if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "  if not os.path.exists(work_dir):\n",
        "    !mkdir -p {work_dir}\n",
        "\n",
        "  print(\"Checking latest version...\")\n",
        "  if os.path.exists(f'{work_dir}/latest_hash.txt'):\n",
        "    current_version_hash = open(f'{work_dir}/latest_hash.txt').read().strip()\n",
        "  else:\n",
        "    current_version_hash = None\n",
        "\n",
        "  !curl -s -L https://huggingface.co/wok000/ttsclient000_colab/resolve/main/latest_hash.txt -o latest_hash.txt\n",
        "  latest_version_hash = open('latest_hash.txt').read().strip()\n",
        "\n",
        "  print(f\"current_version_hash: {current_version_hash}\")\n",
        "  print(f\"latest_version_hash : {latest_version_hash}\")\n",
        "\n",
        "  if current_version_hash != latest_version_hash:\n",
        "    print(f\"hash not match -> download latest version\")\n",
        "\n",
        "    latest_hash_path=f'{work_dir}/latest_hash.txt'\n",
        "\n",
        "    !curl -L https://huggingface.co/wok000/ttsclient000_colab/resolve/main/ttsclient_latest_for_colab -o {work_dir}/ttsclient_latest_for_colab\n",
        "    !curl -L https://huggingface.co/wok000/ttsclient000_colab/resolve/main/web_front_latest.zip -o {work_dir}/web_front_latest.zip\n",
        "\n",
        "    !cp latest_hash.txt {latest_hash_path}\n",
        "    print(\"Download is done.\")\n",
        "  else:\n",
        "    print(\"hash matched. skip download\")\n",
        "\n",
        "else:\n",
        "  work_dir = \"/content\"\n",
        "  print(\"Downloading the latest ttsclient... \")\n",
        "  !curl -s -L https://huggingface.co/wok000/ttsclient000_colab/resolve/main/latest_hash.txt -o latest_hash.txt\n",
        "  latest_version_hash = open('latest_hash.txt').read().strip()\n",
        "\n",
        "  !curl -L https://huggingface.co/wok000/ttsclient000_colab/resolve/main/ttsclient_latest_for_colab -o {work_dir}/ttsclient_latest_for_colab\n",
        "  !curl -L https://huggingface.co/wok000/ttsclient000_colab/resolve/main/web_front_latest.zip -o {work_dir}/web_front_latest.zip\n",
        "\n",
        "  print(\"Download is done.\")\n",
        "\n",
        "%cd {work_dir}\n",
        "!chmod 0700 ttsclient_latest_for_colab\n",
        "\n",
        "print(\"Installing modules... \",end=\"\")\n",
        "!sudo apt-get install -y libportaudio2 > /dev/null 2>&1\n",
        "!pip install  pyngrok > /dev/null 2>&1\n",
        "print(\"Install is done.\")\n",
        "\n",
        "Run_Cell=1\n",
        "\n",
        "!unzip -qq web_front_latest.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7mYqKtW6VOI",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title **[2]** Start server\n",
        "# @markdown This cell will start the server, the first time that you run it will download the models, so it can take a while (2~4 minutes)\n",
        "\n",
        "# @markdown If you want to use ngrok, please input your token in the option section below. If you encounter a 403 error with the colab proxy, using ngrok can sometimes help to work around it.\n",
        "# @markdown https://dashboard.ngrok.com/\n",
        "\n",
        "\n",
        "# @markdown ### Options:\n",
        "ClearConsole = True  # @param {type:\"boolean\"}\n",
        "Play_Notification = True  # @param {type:\"boolean\"}\n",
        "NgrokToken = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "PORT=8005\n",
        "NGROK_URL_FILE = \"ngrok_url.txt\"\n",
        "\n",
        "LOG_FILE = f\"/content/LOG_FILE_{PORT}.log\"\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "def play_notification_sound(url):\n",
        "    display(Audio(url=url, autoplay=True))\n",
        "\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if NgrokToken ==\"\":\n",
        "  get_ipython().system_raw(f'LD_LIBRARY_PATH=/usr/lib64-nvidia:/usr/lib/x86_64-linux-gnu ./ttsclient_latest_for_colab cui --port {PORT} --no_cui true --https False >{LOG_FILE} 2>&1 &')\n",
        "else:\n",
        "  # get_ipython().system_raw(f'LD_LIBRARY_PATH=/usr/lib64-nvidia:/usr/lib/x86_64-linux-gnu ./ttsclient_latest_for_colab cui --port {PORT} --no_cui true --https False --ngrok_token {NgrokToken} --ngrok_proxy_url_file {NGROK_URL_FILE} >{LOG_FILE} 2>&1 &')\n",
        "  get_ipython().system_raw(f'./ttsclient_latest_for_colab cui --port {PORT} --no_cui true --https False --ngrok_token {NgrokToken} --ngrok_proxy_url_file {NGROK_URL_FILE} >{LOG_FILE} 2>&1 &')\n",
        "\n",
        "\n",
        "import socket\n",
        "def wait_for_server():\n",
        "  elapsed_time = 0\n",
        "  start_time = time.time()\n",
        "\n",
        "\n",
        "  while True:\n",
        "      time.sleep(1)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', PORT))\n",
        "      if result == 0:\n",
        "          break\n",
        "      sock.close()\n",
        "      # 時刻を出力\n",
        "      current_time = time.time()\n",
        "      elapsed_time = int(current_time - start_time)\n",
        "      clear_output(wait=True)\n",
        "      print(f\"Waiting for server... elapsed: {elapsed_time}sec\")\n",
        "      try:\n",
        "        with open(LOG_FILE, 'r') as f:\n",
        "            lines = f.readlines()[-5:]\n",
        "            for line in lines:\n",
        "                print(line.strip())\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "  if ClearConsole:\n",
        "      clear_output()\n",
        "  print(\"--------- SERVER READY! ---------\")\n",
        "  print(f\"Your server is available. elapsed: {elapsed_time}sec\")\n",
        "  proxy = eval_js( \"google.colab.kernel.proxyPort(\" + str(PORT) + \")\" )\n",
        "  print(f\"colab proxy: {proxy}\")\n",
        "  if NgrokToken != \"\":\n",
        "    with open(NGROK_URL_FILE, \"r\") as f:\n",
        "      ngrok_url = f.read().strip()\n",
        "    print(f\"Ngrok URL: {ngrok_url}\")\n",
        "  print(\"---------------------------------\")\n",
        "  if Play_Notification==True:\n",
        "    play_notification_sound('https://huggingface.co/wok000/voices/resolve/main/vcclient001_vctk229_gpt-sovits_vcclient-ready.wav')\n",
        "wait_for_server()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **[3]** Start Cell Client (Experimental)\n",
        "# @markdown Launch the client within the cell. This can be used if proxy or ngrok cannot be used.If the behavior is unstable, re-running the cell may resolve the issue.\n",
        "\n",
        "from IPython.display import HTML, SVG,Javascript\n",
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "def dojs3():\n",
        "  return HTML(f\"\"\"\n",
        "<script>var colab_server_port={PORT}</script>\n",
        "<script>var colab_server=1</script>\n",
        "<script defer=\"defer\" src=\"http://localhost:{PORT}/index.js\"></script>\n",
        "<div id=\"app\" style=\"width:100%;height:100%\"></div>\n",
        "  \"\"\")\n",
        "  dojs3()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fIqxDo-rSkrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wmMmQYg6SqVQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNJbNICaabRM9/HwkNUBS15",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}